{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54beabc2-a71d-4539-81b4-548d87b0691e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c94fc9a5-1c4d-48c4-9b4f-d31ebc36a91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the Python executable path\n",
    "os.environ['PYSPARK_PYTHON'] = r'C:\\\\Users\\\\Manideep S\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] =r'C:\\\\Users\\\\Manideep S\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35aeb44c-2a88-4ac7-b1cc-aacd0ef63873",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"session\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ecc8c2b-b7f8-417e-9e2b-6fdb40ebce21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of partitions\n",
    "num_partitions = 5\n",
    "\n",
    "# Base path for partitions in DBFS\n",
    "base_path = r\"C:\\\\Users\\\\Manideep S\\\\OneDrive - COGNINE\\\\ML\\\\Assessments\\\\PySpark\\\\DataSkew-Salting\\\\\"\n",
    "\n",
    "# List to hold DataFrames for each partition\n",
    "dfs = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "196a1d2d-81f6-474a-a1d2-ddc5e6353e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read each partition and add to the list\n",
    "for i in range(1, num_partitions + 1):\n",
    "    partition_path = f'{base_path}partition_{i:02}.csv'\n",
    "    partition_df = spark.read.csv(partition_path, header=True, inferSchema=True)\n",
    "    dfs.append(partition_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3600fbbd-847c-4b60-a72d-63409acfa8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+--------------------+---------+-----------------+\n",
      "|       director_name|            ceremony|  year|            category|  outcome|original_language|\n",
      "+--------------------+--------------------+------+--------------------+---------+-----------------+\n",
      "|         Endre Hules|Montréal World Fi...|2011.0|       Golden Zenith|Nominated|               en|\n",
      "|    Michael Lantieri|Academy of Scienc...|2002.0|        Saturn Award|      Won|               en|\n",
      "|Alessandro Benvenuti|  Golden Ciak Awards|1994.0|         Golden Ciak|      Won|               it|\n",
      "|         David Feiss|        Annie Awards|2017.0|               Annie|Nominated|               en|\n",
      "|        Timo Novotny|  Diagonale, Austria|1998.0|Diagonale Youth J...|      Won|               en|\n",
      "|      Kristian Petri|Göteborg Film Fes...|1996.0|        Dragon Award|      Won|               en|\n",
      "|   Mario Van Peebles|Locarno Internati...|1995.0|      Silver Leopard|      Won|               en|\n",
      "| Jean-Gabriel Périot|San Francisco Int...|2015.0|   Golden Gate Award|Nominated|               en|\n",
      "|         Mick Molloy|Australian Film I...|2003.0|           AFI Award|Nominated|               en|\n",
      "|      Andrey Paounov|Molodist Internat...|2001.0|    Festival Diploma|      Won|               en|\n",
      "|          Ben Safdie|Venice Film Festival|2014.0|    C.I.C.A.E. Award|      Won|               en|\n",
      "|        Lance Hammer|New York Film Cri...|2008.0|         NYFCC Award|2nd place|               en|\n",
      "|  Matt Wu Zhong-Tian|Golden Horse Film...|2006.0|  Golden Horse Award|Nominated|               zh|\n",
      "|    Adam Bhala Lough|Anchorage Interna...|2003.0|        Best Feature|      Won|               en|\n",
      "|     Roberto Moreira|Rio de Janeiro In...|2004.0|     Première Brazil|      Won|               pt|\n",
      "|      Tsutomu Tamura| Kinema Junpo Awards|1970.0|  Kinema Junpo Award|      Won|               en|\n",
      "|  Sebastián Schindel|Chicago Internati...|2014.0|           Gold Hugo|Nominated|               es|\n",
      "|         Judd Apatow|Primetime Emmy Aw...|1993.0|      Primetime Emmy|      Won|               en|\n",
      "|           James Wan|San Sebastián Hor...|2004.0|      Audience Award|      Won|               en|\n",
      "|          Kanye West|       Grammy Awards|2005.0|              Grammy|      Won|               en|\n",
      "+--------------------+--------------------+------+--------------------+---------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combine all partitions into a single DataFrame\n",
    "combined_df = dfs[0]\n",
    "for df in dfs[1:]:\n",
    "    combined_df = combined_df.union(df)\n",
    "# Show the combined DataFrame\n",
    "combined_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a862446d-8208-4dd9-a43a-17383b46ebba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, director_name: string, ceremony: string, year: string, category: string, outcome: string, original_language: string]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "148ac2db-8df3-438f-bb70-d458aafe29c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4b8f5b-4779-49af-94fa-2ccb50829152",
   "metadata": {},
   "source": [
    "# Partioning already read data, repartitioning data and then repartitioning based on salt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309d4fed-9166-4212-be8c-39be3c7b3a18",
   "metadata": {},
   "source": [
    "### No of partitions of already manually partitioned data, experiencing skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c37d46c-ae29-4e66-95ad-d3e38f0c1081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|SPARK_PARTITION_ID()|count|\n",
      "+--------------------+-----+\n",
      "|                   0|53085|\n",
      "|                   1|53112|\n",
      "|                   2| 6640|\n",
      "|                   3|53159|\n",
      "|                   4| 3259|\n",
      "|                   5|28209|\n",
      "|                   6|14104|\n",
      "|                   7| 7052|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined_df.groupBy(F.spark_partition_id()).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980e2f59-9167-4e0b-805d-199c6a6b82bb",
   "metadata": {},
   "source": [
    "### Data read from csv whithout repartioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d92c9946-c93c-4562-a89a-93b23540cc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = spark.read.csv(r\"C:\\Users\\Manideep S\\OneDrive - COGNINE\\ML\\Assessments\\PySpark\\DataSkew-Salting\\220k_awards_by_directors.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45fc8fa1-baa9-4866-b0ec-ef5abc482c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|SPARK_PARTITION_ID()|count|\n",
      "+--------------------+-----+\n",
      "|                   0|54137|\n",
      "|                   1|53598|\n",
      "|                   2|52625|\n",
      "|                   3|51965|\n",
      "|                   4|13350|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "original_df.groupBy(F.spark_partition_id()).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db962d94-4c2b-490a-832d-162f42ef7170",
   "metadata": {},
   "source": [
    "### Repartioning data without salt, evenly distributing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70d1d81b-7e2e-4d2e-8667-b88c3eac826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repartition\n",
    "repartition_combined_df_rp = combined_df.repartition(10, 'director_name', 'ceremony', 'year', 'category', 'outcome', 'original_language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7b25069-7722-4e11-a327-85415dc593c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|SPARK_PARTITION_ID()|count|\n",
      "+--------------------+-----+\n",
      "|                   0|21731|\n",
      "|                   1|21947|\n",
      "|                   2|21775|\n",
      "|                   3|21662|\n",
      "|                   4|21855|\n",
      "|                   5|22095|\n",
      "|                   6|21764|\n",
      "|                   7|21927|\n",
      "|                   8|21856|\n",
      "|                   9|22008|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "repartition_combined_df_rp.groupBy(F.spark_partition_id()).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e339a7-31b0-402e-a4f1-0a32c0b1cfaa",
   "metadata": {},
   "source": [
    "### Adding salt column and repartioning based on salt, shows more evenly distributed data around all the partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9706c1d-0de2-4c87-b9fd-fc8a810c9714",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df_slt = combined_df.withColumn('salt', F.rand())\n",
    "repartition_combined_df_slt = combined_df_slt.repartition(10, 'salt')\n",
    "\n",
    "# df = df.withColumn('salt', F.rand())\n",
    "# df = df.repartition(8, 'salt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64832d4d-e5bd-4e9a-a02b-a424fe616a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|SPARK_PARTITION_ID()|count|\n",
      "+--------------------+-----+\n",
      "|                   0|21833|\n",
      "|                   1|21777|\n",
      "|                   2|21893|\n",
      "|                   3|22047|\n",
      "|                   4|21943|\n",
      "|                   5|22000|\n",
      "|                   6|21843|\n",
      "|                   7|21912|\n",
      "|                   8|21971|\n",
      "|                   9|21401|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "repartition_combined_df_slt.groupBy(F.spark_partition_id()).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725c1d63-8c7a-4e3c-b0cd-14f27191f91d",
   "metadata": {},
   "source": [
    "# Partioning using salting while reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dbad6b6-38fb-49ed-9a19-b68bb059ef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, concat, lit, expr, rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2b45bb-c68b-4f11-95b3-c9595e5fa203",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
